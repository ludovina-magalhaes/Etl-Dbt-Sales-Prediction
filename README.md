#  ETL + dbt + Snowflake: Proyecto de PredicciÃ³n de Ventas

Este proyecto tiene como objetivo construir un pipeline moderno de datos utilizando **dbt (data build tool)** con **Snowflake** como data warehouse, realizando transformaciones y modelado predictivo sobre los datos de ventas del conjunto **BigMart Sales**.

---

##  Stack TecnolÃ³gico

| Capa                  | Herramienta               |
|-----------------------|---------------------------|
| Data Warehouse        | â„ï¸ Snowflake              |
| Transformaciones SQL  | ğŸ“¦ dbt                     |
| AnÃ¡lisis Predictivo   | ğŸ Python (Jupyter Notebook) |
| GestiÃ³n de Dependencias | Poetry                 |
| Control de Versiones  | Git + GitHub              |

---

## Objetivo del Proyecto

- Construir un **pipeline ETL moderno** con dbt.
- Modelar los datos en **capas bronce, plata y oro**.
- Predecir ventas de productos utilizando un modelo de **machine learning supervisado**.
- Almacenar los datos transformados y las predicciones en **Snowflake**.

---

##  Estructura del Proyecto

```
Etl-Dbt-Sales-Prediction/
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ staging/         # Capa Bronce
â”‚   â”œâ”€â”€ intermediate/    # Capa Plata
â”‚   â””â”€â”€ marts/           # Capa Oro (mart de predicciÃ³n)
â”‚
â”œâ”€â”€ seeds/               # Datos fijos o de referencia
â”œâ”€â”€ snapshots/           # Versionado histÃ³rico (si aplica)
â”œâ”€â”€ macros/              # Funciones reutilizables
â”œâ”€â”€ tests/               # Tests de calidad de datos
â”‚
â”œâ”€â”€ Big-Mart-Sales-Prediction.ipynb  # Notebook de machine learning
â”œâ”€â”€ pyproject.toml       # ConfiguraciÃ³n de Poetry
â”œâ”€â”€ README.md            # Este archivo
```

---

##  CÃ³mo Ejecutar

### 1. Clonar el repositorio

```bash
git clone https://github.com/ludovina-magalhaes/Etl-Dbt-Sales-Prediction.git
cd Etl-Dbt-Sales-Prediction
```

### 2. Configurar entorno dbt + Snowflake

Crea un archivo `~/.dbt/profiles.yml` con el siguiente contenido:

```yaml
etl_dbt_sales:
  target: dev
  outputs:
    dev:
      type: snowflake
      account: <tu_cuenta>.snowflakecomputing.com
      user: <tu_usuario>
      password: <tu_contraseÃ±a>
      role: <tu_rol>
      database: <tu_base_de_datos>
      warehouse: <tu_almacen>
      schema: <tu_esquema>
      threads: 4
```

>  RecomendaciÃ³n: usa variables de entorno o dbt Cloud para mayor seguridad.

### 3. Instalar las dependencias dbt

```bash
poetry install
```

### 4. Ejecutar el pipeline

```bash
dbt debug
dbt run
dbt test
dbt docs generate
```

---

## ğŸ”¬ Pruebas y DocumentaciÃ³n

###  Tests de calidad de datos

Se han aÃ±adido tests `not_null`, `unique`, y otros para garantizar la integridad de los datos en los modelos dbt.

Ejemplo (`schema.yml`):

```yaml
models:
  - name: sales_final
    description: "Tabla final con datos de ventas preparados para predicciÃ³n."
    columns:
      - name: id_venta
        description: "Identificador Ãºnico de la venta."
        tests: [not_null, unique]
      - name: fecha_venta
        description: "Fecha en la que ocurriÃ³ la venta."
        tests: [not_null]
```

###  DocumentaciÃ³n

Todos los modelos y columnas estÃ¡n documentados utilizando `description` y bloques `docs`. La documentaciÃ³n puede visualizarse con:

```bash
dbt docs generate
dbt docs serve
```

---

##  Modelado Predictivo

El notebook `Big-Mart-Sales-Prediction.ipynb` contiene:

- Limpieza y preparaciÃ³n de los datos.
- ExploraciÃ³n de variables.
- CreaciÃ³n de caracterÃ­sticas (features).
- Entrenamiento de un modelo predictivo (por ejemplo, RegresiÃ³n Lineal, XGBoost).
- GeneraciÃ³n de predicciones integradas con Snowflake (a travÃ©s del conector de Python).

---

##  Licencia

Este proyecto estÃ¡ licenciado bajo la licencia **MIT**.

---

## ğŸ“š Recursos Ãštiles

- [DocumentaciÃ³n oficial de dbt](https://docs.getdbt.com/)
- [Foro dbt Discourse](https://discourse.getdbt.com/)
- [Comunidad dbt en Slack](https://community.getdbt.com/)
- [Eventos dbt cerca de ti](https://events.getdbt.com/)
- [Blog oficial de dbt](https://www.getdbt.com/blog/)
